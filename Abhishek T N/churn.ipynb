{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'D:\\Infosys springboard\\churn_data\\Churn_ Data.csv'  \n",
    "data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the dataset:\n",
      "   s6.new.rev.p2.m2  s1.new.rev.m1  s3.og.rev.4db.p5  s3.new.rev.4db.p5  \\\n",
      "0             -0.76        88.0482          3.106604           3.754955   \n",
      "1             -0.98        67.5039          3.094574           5.550865   \n",
      "2             -0.98        33.9248          2.324016           2.438114   \n",
      "3             -0.92        82.6780          2.630749           2.858961   \n",
      "4             -0.97        96.8379          2.674316           2.912397   \n",
      "\n",
      "   s4.usg.ins.p2  s4.og.unq.any.p2  s2.rch.val.p6  s1.og.rev.all.m1  \\\n",
      "0              4                14          39.29            57.320   \n",
      "1              1                 2          21.67            38.700   \n",
      "2              2                 3          30.00            15.320   \n",
      "3              2                 3          50.00            51.956   \n",
      "4              3                 2          22.50            66.886   \n",
      "\n",
      "   s8.new.rev.p6  s4.loc.ic.ins.p1  ...  prop.og.mou.tot.mou.all.p6  \\\n",
      "0          -0.17                 1  ...                    0.454642   \n",
      "1          -0.32                 3  ...                    0.343190   \n",
      "2          -0.05                 3  ...                    0.101838   \n",
      "3          -0.18                 4  ...                    0.066602   \n",
      "4           0.01                 4  ...                    0.219821   \n",
      "\n",
      "   prop.i2i.og.mou.p6  s4.loc.ic.ins.p2  s4.std.ic.ins.l14  \\\n",
      "0            0.497397                 4                  0   \n",
      "1            0.767617                 6                  0   \n",
      "2            0.619034                 6                  1   \n",
      "3            0.437088                 7                  2   \n",
      "4            0.585977                 6                  1   \n",
      "\n",
      "   s4.low.blnc.ins.p4  s3.og.rev.all.m2  s3.new.rev.m2  prop.og.mou.any.p6  \\\n",
      "0                   9              6.02           8.20           46.465636   \n",
      "1                  20              3.66           8.10           34.525456   \n",
      "2                  19              4.33           4.36           10.298451   \n",
      "3                  11              3.40           3.53            6.670783   \n",
      "4                  14              3.85           3.87           21.998905   \n",
      "\n",
      "   prop.loc.i2i.mou.og.mou.p3  s3.rev.p1  \n",
      "0                    0.609456       0.22  \n",
      "1                    1.000000       0.38  \n",
      "2                    0.699592       0.11  \n",
      "3                    0.086617       5.18  \n",
      "4                    0.683105       0.10  \n",
      "\n",
      "[5 rows x 111 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of the dataset\n",
    "print(\"First few rows of the dataset:\")\n",
    "print(data.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of the dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25000 entries, 0 to 24999\n",
      "Columns: 111 entries, s6.new.rev.p2.m2 to s3.rev.p1\n",
      "dtypes: float64(80), int64(31)\n",
      "memory usage: 21.2 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Summary of the dataset\n",
    "print(\"\\nSummary of the dataset:\")\n",
    "print(data.info())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic statistics of the dataset:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       s6.new.rev.p2.m2  s1.new.rev.m1  s3.og.rev.4db.p5  s3.new.rev.4db.p5  \\\n",
      "count      25000.000000   25000.000000      25000.000000       25000.000000   \n",
      "mean          -0.003730     281.073083          4.890003           7.070194   \n",
      "std            2.727916     276.075983          4.212452           6.318992   \n",
      "min           -1.000000       0.000000          0.000000           0.000833   \n",
      "25%           -0.580000     101.563800          2.367288           3.318825   \n",
      "50%           -0.170000     204.859600          3.729944           5.231268   \n",
      "75%            0.280000     370.711650          5.993342           8.395736   \n",
      "max          316.860000    5702.924300        153.221695         170.200441   \n",
      "\n",
      "       s4.usg.ins.p2  s4.og.unq.any.p2  s2.rch.val.p6  s1.og.rev.all.m1  \\\n",
      "count   25000.000000      25000.000000   25000.000000      25000.000000   \n",
      "mean        5.460080         28.532520      72.208906        218.517937   \n",
      "std         2.184444         28.061435      67.921490        231.321064   \n",
      "min         0.000000          0.000000       0.000000          0.000000   \n",
      "25%         5.000000          9.000000      33.000000         74.420000   \n",
      "50%         7.000000         21.000000      52.260000        151.168500   \n",
      "75%         7.000000         39.000000      89.852500        284.265000   \n",
      "max         7.000000        622.000000    2249.000000       3767.565000   \n",
      "\n",
      "       s8.new.rev.p6  s4.loc.ic.ins.p1  ...  prop.og.mou.tot.mou.all.p6  \\\n",
      "count   25000.000000      25000.000000  ...                25000.000000   \n",
      "mean       -0.028327          3.254720  ...                    0.538407   \n",
      "std         0.354573          1.193271  ...                    0.209203   \n",
      "min        -5.090000          0.000000  ...                    0.000000   \n",
      "25%        -0.160000          3.000000  ...                    0.394227   \n",
      "50%        -0.020000          4.000000  ...                    0.539354   \n",
      "75%         0.110000          4.000000  ...                    0.682695   \n",
      "max         5.000000          4.000000  ...                    1.000000   \n",
      "\n",
      "       prop.i2i.og.mou.p6  s4.loc.ic.ins.p2  s4.std.ic.ins.l14  \\\n",
      "count        25000.000000      25000.000000       25000.000000   \n",
      "mean             0.485523          5.731280           1.797320   \n",
      "std              0.271146          1.936848           3.048943   \n",
      "min              0.000000          0.000000           0.000000   \n",
      "25%              0.274034          5.000000           0.000000   \n",
      "50%              0.476759          7.000000           0.000000   \n",
      "75%              0.694104          7.000000           2.000000   \n",
      "max              1.000000          7.000000          14.000000   \n",
      "\n",
      "       s4.low.blnc.ins.p4  s3.og.rev.all.m2  s3.new.rev.m2  \\\n",
      "count        25000.000000      25000.000000   25000.000000   \n",
      "mean             8.382160          8.008660      12.540182   \n",
      "std              8.961016          6.152429      11.540611   \n",
      "min              0.000000          0.000000       0.000000   \n",
      "25%              1.000000          4.207500       6.167500   \n",
      "50%              5.000000          6.345000       9.350000   \n",
      "75%             14.000000          9.830000      14.620000   \n",
      "max             30.000000        171.780000     386.480000   \n",
      "\n",
      "       prop.og.mou.any.p6  prop.loc.i2i.mou.og.mou.p3     s3.rev.p1  \n",
      "count        25000.000000                25000.000000  25000.000000  \n",
      "mean            53.594165                    0.483975      9.951366  \n",
      "std             21.408486                    0.292349     17.648128  \n",
      "min              0.000000                    0.000000      0.000000  \n",
      "25%             39.378142                    0.251304      1.970000  \n",
      "50%             53.976203                    0.477621      5.380000  \n",
      "75%             68.312416                    0.716538     11.400000  \n",
      "max            100.000000                    1.000000    585.500000  \n",
      "\n",
      "[8 rows x 111 columns]\n"
     ]
    }
   ],
   "source": [
    "# Basic statistics of the dataset\n",
    "print(\"\\nBasic statistics of the dataset:\")\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 111)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in data.columns:\n",
    "    data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 111)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Remove Duplicate Records\n",
    "data = data.drop_duplicates()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Remove Unique Value Variables\n",
    "unique_counts = data.nunique()\n",
    "cols_to_drop = unique_counts[unique_counts == len(data)].index\n",
    "data = data.drop(cols_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Remove Zero Variance Variables\n",
    "var_thresh = VarianceThreshold(threshold=0)\n",
    "var_thresh.fit(data)\n",
    "zero_variance_cols = data.columns[~var_thresh.get_support()]\n",
    "data = data.drop(zero_variance_cols, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Outlier Treatment\n",
    "\n",
    "# Using Boxplot Method\n",
    "Q1 = data.quantile(0.25)\n",
    "Q3 = data.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "data = data.clip(lower=(Q1 - 1.5 * IQR), upper=(Q3 + 1.5 * IQR), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 111)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardization Method (3-sigma approach)\n",
    "scaler = StandardScaler()\n",
    "z_scores = np.abs(scaler.fit_transform(data.select_dtypes(include=[np.number])))\n",
    "data[(z_scores > 3).any(axis=1)] = np.nan\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Missing Values Analysis:\n",
      "                       Total  Percentage\n",
      "s6.new.rev.p2.m2         651       2.604\n",
      "s8.rtd.mou.p3            651       2.604\n",
      "s8.og.mou.all.p6         651       2.604\n",
      "s7.s5.s4.day.nomou.p2    651       2.604\n",
      "s3.rtd.mou.p1            651       2.604\n",
      "...                      ...         ...\n",
      "s3.og.mou.all.p1         651       2.604\n",
      "snd.dec.p2               651       2.604\n",
      "ds.usg.p6                651       2.604\n",
      "s7.new.rev.p3.p6         651       2.604\n",
      "s3.rev.p1                651       2.604\n",
      "\n",
      "[111 rows x 2 columns]\n",
      "Cleaned data shape: (24349, 111)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 1: Analyze the missing values\n",
    "def analyze_missing_values(df):\n",
    "    missing_data = df.isnull().sum().sort_values(ascending=False)\n",
    "    missing_percentage = (df.isnull().sum() / df.isnull().count() * 100).sort_values(ascending=False)\n",
    "    missing_df = pd.concat([missing_data, missing_percentage], axis=1, keys=['Total', 'Percentage'])\n",
    "    return missing_df\n",
    "\n",
    "# Display the initial missing values analysis\n",
    "initial_missing_values = analyze_missing_values(data)\n",
    "print(\"Initial Missing Values Analysis:\")\n",
    "print(initial_missing_values)\n",
    "\n",
    "# Step 2: Remove records with more than 5% missing values\n",
    "threshold = data.shape[1] * 0.95\n",
    "data = data.dropna(thresh=int(threshold))\n",
    "\n",
    "print(f\"Cleaned data shape: {data.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data shape: (24349, 111)\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Remove columns with more than 50% missing values\n",
    "threshold = data.shape[0] * 0.5\n",
    "data = data.loc[:, data.isnull().sum() <= threshold]\n",
    "print(f\"Cleaned data shape: {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric columns: ['s6.new.rev.p2.m2', 's1.new.rev.m1', 's3.og.rev.4db.p5', 's3.new.rev.4db.p5', 's4.usg.ins.p2', 's4.og.unq.any.p2', 's2.rch.val.p6', 's1.og.rev.all.m1', 's8.new.rev.p6', 's4.loc.ic.ins.p1', 's8.mbl.p2', 's2.rch.val.l67', 's7.s4.day.no.mou.p2.p4', 's3.new.rev.p3', 's7.s5.s4.day.nomou.p4', 's8.og.rev.p3', 's8.ic.mou.all.p3', 'target', 's7.new.rev.p2.p6', 's6.rtd.mou.p2.m2', 's7.rtd.mou.p2.p6', 's1.new.rev.p2', 's1.new.rev.p1', 's1.og.hom.mou.p1', 's7.rev.p2.p6', 's1.og.hom.rev.p2', 's1.rtd.mou.p1', 's1.og.rev.all.p1', 's1.og.mou.all.p1', 's3.og.rev.all.p1', 's7.new.rev.p3.p6', 'ds.usg.p6', 'snd.dec.p2', 's3.og.mou.all.p1', 'ds.og.usg.p4', 's1.og.mou.all.p2', 's8.og.rev.p6', 's1.og.hom.mou.p2', 's5.og.rev.all.p1', 's1.og.rev.all.p2', 's1.rtd.mou.p2', 's5.rtd.mou.p1', 's1.og.mou.any.p2', 's4.day.no.mou.p2', 's1.hom.rmg.rev.p2', 's7.rtd.mou.p3.p6', 's5.og.mou.all.p1', 's5.og.hom.mou.p1', 's3.new.rev.p1', 's4.usg.ins.p1', 's2.s4.day.no.mou.p2', 's7.new.rev.l21.p6', 's5.rev.p1', 's5.s4.day.no.mou.p2', 'tot.s4.day.no.mou.p2', 's8.new.rev.p3', 's3.og.mou.all.p2', 's1.rev.p1', 's4.loc.og.ins.p1', 's1.loc.og.mou.p1', 's4.og.any.p2', 'prop.og.mou.any.p2', 's4.low.blnc.ins.p3', 's1.loc.og.mou.p2', 's5.new.rev.p2', 's5.new.rev.p1', 's4.low.blnc.ins.l14', 's3.og.hom.mou.p1', 's7.rtd.mou.l21.p6', 's4.loc.og.ins.l14', 's8.rtd.mou.p3', 's4.dec.ins.l14', 's2.s4.day.no.mou.p3', 's3.new.rev.p2', 'tot.s4.day.no.mou.p3', 's5.og.mou.all.p2', 's4.loc.ic.ins.l14', 's4.usg.ins.l14', 's4.loc.og.ins.p2', 's3.rtd.mou.p1', 's7.s5.s4.day.nomou.p2', 's8.og.mou.all.p6', 's5.og.hom.mou.p2', 's7.rtd.mou.m1.m2', 'prop.og.mou.tot.mou.all.p2', 's8.rev.p6', 's7.s5.s4.day.nomou.p3', 's5.rev.p2', 's1.new.rev.m2', 's3.og.rev.3db.p5', 's4.rch.val.gt.30.p2', 's8.rtd.mou.p6', 's4.std.ins.l14', 's4.low.blnc.ins.p2', 's4.low.blnc.ins.p6', 's4.loc.ins.l14', 's4.low.blnc.ins.m2', 's4.data.ins.l14', 'prop.loc.i2i.mou.og.mou.p6', 's4.dec.ins.p2', 's1.rev.p2', 'prop.og.mou.tot.mou.all.p6', 'prop.i2i.og.mou.p6', 's4.loc.ic.ins.p2', 's4.std.ic.ins.l14', 's4.low.blnc.ins.p4', 's3.og.rev.all.m2', 's3.new.rev.m2', 'prop.og.mou.any.p6', 'prop.loc.i2i.mou.og.mou.p3', 's3.rev.p1']\n",
      "Categorical columns: []\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Step 1: Analyze the data types\n",
    "def analyze_data_types(df):\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    return numeric_cols, categorical_cols\n",
    "\n",
    "numeric_cols, categorical_cols = analyze_data_types(data)\n",
    "print(\"Numeric columns:\", numeric_cols)\n",
    "print(\"Categorical columns:\", categorical_cols)\n",
    "# Step 2: Encode categorical columns before KNN imputation\n",
    "data_encoded = data.copy()\n",
    "for col in categorical_cols:\n",
    "    data_encoded[col] = data_encoded[col].astype('category').cat.codes\n",
    "\n",
    "\"\"\"K-Nearest Neighbors (KNN) imputation is a method used to fill in missing values in a dataset\n",
    " by leveraging the information from the 'nearest' observations.\"\"\"\n",
    "\n",
    "# Step 3: KNN Imputation\n",
    "knn_imputer = KNNImputer(n_neighbors=5)\n",
    "data_imputed = knn_imputer.fit_transform(data_encoded)\n",
    "\n",
    "# Convert back to DataFrame\n",
    "data_imputed = pd.DataFrame(data_imputed, columns=data.columns)\n",
    "\n",
    "# Decode categorical columns after imputation\n",
    "for col in categorical_cols:\n",
    "    data_imputed[col] = data_imputed[col].round().astype(int).astype('category')\n",
    "    data_imputed[col] = data_imputed[col].cat.rename_categories(data[col].astype('category').cat.categories)\n",
    "\n",
    "data = data_imputed.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24349, 34)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 7: Removing Highly Correlated Variables\n",
    "corr_matrix = data.corr().abs()\n",
    "upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.8)]\n",
    "data = data.drop(to_drop, axis=1)\n",
    "data.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multicollinearity occurs when two or more predictor variables in a multiple regression model are highly correlated\n",
    "Variance Inflation Factor (VIF) is a metric used to detect the presence of multicollinearity in a set of predictor variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1754: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return 1 - self.ssr/self.uncentered_tss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Pre-processing Completed\n",
      "(24349, 22)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Assuming 'data' is your DataFrame\n",
    "# data = pd.read_csv('your_data.csv')\n",
    "\n",
    "def calculate_vif(df):\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"feature\"] = df.columns\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(df.values, i) for i in range(df.shape[1])]\n",
    "    return vif_data\n",
    "\n",
    "# Keep dropping features with high VIF until all VIF values are <= 5\n",
    "while True:\n",
    "    numeric_data = data.select_dtypes(include=[np.number])\n",
    "    vif_data = calculate_vif(numeric_data)\n",
    "    high_vif = vif_data[vif_data[\"VIF\"] > 8]\n",
    "    if high_vif.empty:\n",
    "        break\n",
    "    feature_to_drop = high_vif.iloc[0][\"feature\"]\n",
    "    data = data.drop(columns=[feature_to_drop])\n",
    "\n",
    "print(\"Data Pre-processing Completed\")\n",
    "print(data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Pairplot of a subset of the dataset\\nsubset = data.sample(100)  # Sampling for visualization purposes\\nsns.pairplot(subset)\\nplt.show() '"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Pairplot of a subset of the dataset\n",
    "subset = data.sample(100)  # Sampling for visualization purposes\n",
    "sns.pairplot(subset)\n",
    "plt.show() \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('target', axis=1)\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Standardize the feature variables\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Decision Tree Classifier\n",
    "clf = DecisionTreeClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': [None, 'sqrt', 'log2']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=None, min_samples_leaf=2, min_samples_split=2; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=None, min_samples_leaf=2, min_samples_split=2; total time=   0.7s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=None, min_samples_leaf=2, min_samples_split=2; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, max_features=None, min_samples_leaf=2, min_samples_split=2; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=None, max_features=None, min_samples_leaf=2, min_samples_split=2; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=None, max_features=None, min_samples_leaf=2, min_samples_split=2; total time=   0.6s\n",
      "[CV] END criterion=entropy, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=None, min_samples_leaf=2, min_samples_split=5; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=None, min_samples_leaf=2, min_samples_split=5; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=None, min_samples_leaf=2, min_samples_split=5; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=None, min_samples_leaf=2, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=None, min_samples_leaf=2, min_samples_split=2; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=None, min_samples_leaf=2, min_samples_split=2; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=None, min_samples_leaf=1, min_samples_split=5; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=None, min_samples_leaf=1, min_samples_split=5; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=None, min_samples_leaf=1, min_samples_split=5; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=None, min_samples_leaf=4, min_samples_split=5; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=None, min_samples_leaf=4, min_samples_split=5; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=None, min_samples_leaf=4, min_samples_split=5; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=2; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=2; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=2; total time=   0.2s\n",
      "[CV] END criterion=gini, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=5; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=None, max_features=None, min_samples_leaf=2, min_samples_split=5; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=None, max_features=None, min_samples_leaf=2, min_samples_split=5; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=None, max_features=None, min_samples_leaf=2, min_samples_split=5; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=None, min_samples_leaf=2, min_samples_split=2; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=None, min_samples_leaf=2, min_samples_split=2; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=None, min_samples_leaf=2, min_samples_split=2; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=2; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=None, min_samples_leaf=2, min_samples_split=2; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=None, min_samples_leaf=2, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=None, min_samples_leaf=2, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=None, min_samples_leaf=2, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=None, min_samples_leaf=2, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=None, min_samples_leaf=2, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=5; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=5; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=5; total time=   0.2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=DecisionTreeClassifier(random_state=42),\n",
       "                   n_iter=50, n_jobs=1,\n",
       "                   param_distributions={'criterion': ['gini', 'entropy'],\n",
       "                                        'max_depth': [None, 10, 20, 30],\n",
       "                                        'max_features': [None, 'sqrt', 'log2'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10]},\n",
       "                   random_state=42, verbose=2)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use RandomizedSearchCV for hyperparameter tuning\n",
    "random_search = RandomizedSearchCV(estimator=clf, param_distributions=param_grid, n_iter=50, cv=3, n_jobs=1, verbose=2, random_state=42)\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best estimator from the random search\n",
    "best_clf = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = best_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': None, 'max_depth': 10, 'criterion': 'entropy'}\n",
      "Accuracy: 0.7728952772073922\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.88      0.84      3365\n",
      "         1.0       0.66      0.54      0.60      1505\n",
      "\n",
      "    accuracy                           0.77      4870\n",
      "   macro avg       0.74      0.71      0.72      4870\n",
      "weighted avg       0.76      0.77      0.77      4870\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2947  418]\n",
      " [ 688  817]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the feature importances\n",
    "importances = best_clf.feature_importances_\n",
    "feature_names = X.columns\n",
    "feature_importances = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "feature_importances = feature_importances.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importances)\n",
    "plt.title('Feature Importances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Logistic Regression***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Logistic Regression Classifier\n",
    "clf = LogisticRegression(random_state=42, max_iter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['lbfgs', 'liblinear', 'saga'],\n",
    "    'l1_ratio': [None, 0.15, 0.5, 0.85]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "[CV] END .C=0.001, l1_ratio=0.85, penalty=none, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .C=0.001, l1_ratio=0.85, penalty=none, solver=lbfgs; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
      "  \"(penalty={})\".format(self.penalty)\n",
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
      "  \"(penalty={})\".format(self.penalty)\n",
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
      "  \"(penalty={})\".format(self.penalty)\n",
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .C=0.001, l1_ratio=0.85, penalty=none, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ...C=1, l1_ratio=0.15, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END ...C=1, l1_ratio=0.15, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END ...C=1, l1_ratio=0.15, penalty=l1, solver=liblinear; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  \"(penalty={})\".format(self.penalty)\n",
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  \"(penalty={})\".format(self.penalty)\n",
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  \"(penalty={})\".format(self.penalty)\n",
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  \"(penalty={})\".format(self.penalty)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .C=100, l1_ratio=0.15, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END .C=100, l1_ratio=0.15, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END .C=100, l1_ratio=0.15, penalty=l2, solver=liblinear; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  \"(penalty={})\".format(self.penalty)\n",
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  \"(penalty={})\".format(self.penalty)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.001, l1_ratio=0.85, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.001, l1_ratio=0.85, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.001, l1_ratio=0.85, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...C=1, l1_ratio=0.85, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END ...C=1, l1_ratio=0.85, penalty=l1, solver=liblinear; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  \"(penalty={})\".format(self.penalty)\n",
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  \"(penalty={})\".format(self.penalty)\n",
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  \"(penalty={})\".format(self.penalty)\n",
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...C=1, l1_ratio=0.85, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END .C=0.001, l1_ratio=None, penalty=none, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .C=0.001, l1_ratio=None, penalty=none, solver=lbfgs; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  \"(penalty={})\".format(self.penalty)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .C=0.001, l1_ratio=None, penalty=none, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.001, l1_ratio=0.85, penalty=none, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.001, l1_ratio=0.85, penalty=none, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.001, l1_ratio=0.85, penalty=none, solver=liblinear; total time=   0.0s\n",
      "[CV] END ....C=1, l1_ratio=0.5, penalty=l2, solver=liblinear; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  \"(penalty={})\".format(self.penalty)\n",
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  \"(penalty={})\".format(self.penalty)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....C=1, l1_ratio=0.5, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ....C=1, l1_ratio=0.5, penalty=l2, solver=liblinear; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  \"(penalty={})\".format(self.penalty)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......C=0.01, l1_ratio=0.5, penalty=l2, solver=saga; total time=   0.1s\n",
      "[CV] END ......C=0.01, l1_ratio=0.5, penalty=l2, solver=saga; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  \"(penalty={})\".format(self.penalty)\n",
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  \"(penalty={})\".format(self.penalty)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......C=0.01, l1_ratio=0.5, penalty=l2, solver=saga; total time=   0.1s\n",
      "[CV] END ......C=10, l1_ratio=None, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=10, l1_ratio=None, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=10, l1_ratio=None, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=10, l1_ratio=0.5, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=10, l1_ratio=0.5, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=10, l1_ratio=0.5, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..C=0.001, l1_ratio=0.5, penalty=none, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..C=0.001, l1_ratio=0.5, penalty=none, solver=lbfgs; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
      "  \"(penalty={})\".format(self.penalty)\n",
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
      "  \"(penalty={})\".format(self.penalty)\n",
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
      "  \"(penalty={})\".format(self.penalty)\n",
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..C=0.001, l1_ratio=0.5, penalty=none, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.1, l1_ratio=0.15, penalty=elasticnet, solver=saga; total time=   0.2s\n",
      "[CV] END C=0.1, l1_ratio=0.15, penalty=elasticnet, solver=saga; total time=   0.1s\n",
      "[CV] END C=0.1, l1_ratio=0.15, penalty=elasticnet, solver=saga; total time=   0.1s\n",
      "[CV] END .....C=100, l1_ratio=0.85, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=100, l1_ratio=0.85, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=100, l1_ratio=0.85, penalty=l2, solver=lbfgs; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  \"(penalty={})\".format(self.penalty)\n",
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  \"(penalty={})\".format(self.penalty)\n",
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  \"(penalty={})\".format(self.penalty)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, l1_ratio=None, penalty=elasticnet, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.01, l1_ratio=None, penalty=elasticnet, solver=saga; total time=   0.0s\n",
      "[CV] END C=0.01, l1_ratio=None, penalty=elasticnet, solver=saga; total time=   0.0s\n",
      "[CV] END .......C=10, l1_ratio=0.5, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .......C=10, l1_ratio=0.5, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .......C=10, l1_ratio=0.5, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....C=0.001, l1_ratio=None, penalty=l2, solver=saga; total time=   0.1s\n",
      "[CV] END ....C=0.001, l1_ratio=None, penalty=l2, solver=saga; total time=   0.1s\n",
      "[CV] END ....C=0.001, l1_ratio=None, penalty=l2, solver=saga; total time=   0.1s\n",
      "[CV] END C=10, l1_ratio=0.5, penalty=elasticnet, solver=saga; total time=   0.4s\n",
      "[CV] END C=10, l1_ratio=0.5, penalty=elasticnet, solver=saga; total time=   0.2s\n",
      "[CV] END C=10, l1_ratio=0.5, penalty=elasticnet, solver=saga; total time=   0.1s\n",
      "[CV] END ....C=10, l1_ratio=0.85, penalty=none, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....C=10, l1_ratio=0.85, penalty=none, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....C=10, l1_ratio=0.85, penalty=none, solver=lbfgs; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
      "  \"(penalty={})\".format(self.penalty)\n",
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
      "  \"(penalty={})\".format(self.penalty)\n",
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
      "  \"(penalty={})\".format(self.penalty)\n",
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  \"(penalty={})\".format(self.penalty)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....C=0.01, l1_ratio=0.5, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.01, l1_ratio=0.5, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.01, l1_ratio=0.5, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=100, l1_ratio=0.5, penalty=l2, solver=lbfgs; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  \"(penalty={})\".format(self.penalty)\n",
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  \"(penalty={})\".format(self.penalty)\n",
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  \"(penalty={})\".format(self.penalty)\n",
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  \"(penalty={})\".format(self.penalty)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......C=100, l1_ratio=0.5, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=100, l1_ratio=0.5, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....C=0.01, l1_ratio=0.85, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....C=0.01, l1_ratio=0.85, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....C=0.01, l1_ratio=0.85, penalty=l1, solver=lbfgs; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  \"(penalty={})\".format(self.penalty)\n",
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  \"(penalty={})\".format(self.penalty)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......C=0.1, l1_ratio=0.15, penalty=l2, solver=saga; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  \"(penalty={})\".format(self.penalty)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......C=0.1, l1_ratio=0.15, penalty=l2, solver=saga; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  \"(penalty={})\".format(self.penalty)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......C=0.1, l1_ratio=0.15, penalty=l2, solver=saga; total time=   0.1s\n",
      "[CV] END C=100, l1_ratio=0.85, penalty=none, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=100, l1_ratio=0.85, penalty=none, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=100, l1_ratio=0.85, penalty=none, solver=liblinear; total time=   0.0s\n",
      "[CV] END .C=0.01, l1_ratio=0.5, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END .C=0.01, l1_ratio=0.5, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END .C=0.01, l1_ratio=0.5, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=100, l1_ratio=None, penalty=none, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=100, l1_ratio=None, penalty=none, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=100, l1_ratio=None, penalty=none, solver=liblinear; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  \"(penalty={})\".format(self.penalty)\n",
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  \"(penalty={})\".format(self.penalty)\n",
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  \"(penalty={})\".format(self.penalty)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.1, l1_ratio=0.85, penalty=elasticnet, solver=saga; total time=   0.1s\n",
      "[CV] END C=0.1, l1_ratio=0.85, penalty=elasticnet, solver=saga; total time=   0.2s\n",
      "[CV] END C=0.1, l1_ratio=0.85, penalty=elasticnet, solver=saga; total time=   0.2s\n",
      "[CV] END .......C=1, l1_ratio=None, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .......C=1, l1_ratio=None, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .......C=1, l1_ratio=None, penalty=l2, solver=lbfgs; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  \"(penalty={})\".format(self.penalty)\n",
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  \"(penalty={})\".format(self.penalty)\n",
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  \"(penalty={})\".format(self.penalty)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....C=0.1, l1_ratio=0.15, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.1, l1_ratio=0.15, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.1, l1_ratio=0.15, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....C=0.01, l1_ratio=0.15, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....C=0.01, l1_ratio=0.15, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....C=0.01, l1_ratio=0.15, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.1, l1_ratio=None, penalty=l2, solver=saga; total time=   0.1s\n",
      "[CV] END ......C=0.1, l1_ratio=None, penalty=l2, solver=saga; total time=   0.1s\n",
      "[CV] END ......C=0.1, l1_ratio=None, penalty=l2, solver=saga; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  \"(penalty={})\".format(self.penalty)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ........C=1, l1_ratio=0.85, penalty=l2, solver=saga; total time=   0.1s\n",
      "[CV] END ........C=1, l1_ratio=0.85, penalty=l2, solver=saga; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  \"(penalty={})\".format(self.penalty)\n",
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  \"(penalty={})\".format(self.penalty)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ........C=1, l1_ratio=0.85, penalty=l2, solver=saga; total time=   0.2s\n",
      "[CV] END .C=1, l1_ratio=None, penalty=none, solver=liblinear; total time=   0.0s\n",
      "[CV] END .C=1, l1_ratio=None, penalty=none, solver=liblinear; total time=   0.0s\n",
      "[CV] END .C=1, l1_ratio=None, penalty=none, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=10, l1_ratio=0.85, penalty=elasticnet, solver=saga; total time=   0.2s\n",
      "[CV] END C=10, l1_ratio=0.85, penalty=elasticnet, solver=saga; total time=   0.1s\n",
      "[CV] END C=10, l1_ratio=0.85, penalty=elasticnet, solver=saga; total time=   0.1s\n",
      "[CV] END .......C=1, l1_ratio=0.85, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .......C=1, l1_ratio=0.85, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .......C=1, l1_ratio=0.85, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ........C=1, l1_ratio=0.5, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ........C=1, l1_ratio=0.5, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ........C=1, l1_ratio=0.5, penalty=l1, solver=lbfgs; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  \"(penalty={})\".format(self.penalty)\n",
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  \"(penalty={})\".format(self.penalty)\n",
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  \"(penalty={})\".format(self.penalty)\n",
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  \"(penalty={})\".format(self.penalty)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......C=10, l1_ratio=0.85, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=10, l1_ratio=0.85, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=10, l1_ratio=0.85, penalty=l2, solver=lbfgs; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  \"(penalty={})\".format(self.penalty)\n",
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  \"(penalty={})\".format(self.penalty)\n",
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
      "  \"(penalty={})\".format(self.penalty)\n",
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....C=0.1, l1_ratio=0.85, penalty=none, solver=saga; total time=   0.1s\n",
      "[CV] END ....C=0.1, l1_ratio=0.85, penalty=none, solver=saga; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
      "  \"(penalty={})\".format(self.penalty)\n",
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
      "  \"(penalty={})\".format(self.penalty)\n",
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....C=0.1, l1_ratio=0.85, penalty=none, solver=saga; total time=   0.2s\n",
      "[CV] END C=10, l1_ratio=None, penalty=none, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=10, l1_ratio=None, penalty=none, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=10, l1_ratio=None, penalty=none, solver=liblinear; total time=   0.0s\n",
      "[CV] END ...C=0.1, l1_ratio=0.15, penalty=none, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...C=0.1, l1_ratio=0.15, penalty=none, solver=lbfgs; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
      "  \"(penalty={})\".format(self.penalty)\n",
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
      "  \"(penalty={})\".format(self.penalty)\n",
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
      "  \"(penalty={})\".format(self.penalty)\n",
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...C=0.1, l1_ratio=0.15, penalty=none, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=1, l1_ratio=0.15, penalty=none, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=1, l1_ratio=0.15, penalty=none, solver=lbfgs; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
      "  \"(penalty={})\".format(self.penalty)\n",
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
      "  \"(penalty={})\".format(self.penalty)\n",
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
      "  \"(penalty={})\".format(self.penalty)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....C=1, l1_ratio=0.15, penalty=none, solver=lbfgs; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  \"(penalty={})\".format(self.penalty)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......C=100, l1_ratio=0.15, penalty=l1, solver=saga; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  \"(penalty={})\".format(self.penalty)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......C=100, l1_ratio=0.15, penalty=l1, solver=saga; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  \"(penalty={})\".format(self.penalty)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......C=100, l1_ratio=0.15, penalty=l1, solver=saga; total time=   0.2s\n",
      "[CV] END ......C=1, l1_ratio=None, penalty=none, solver=saga; total time=   0.1s\n",
      "[CV] END ......C=1, l1_ratio=None, penalty=none, solver=saga; total time=   0.1s\n",
      "[CV] END ......C=1, l1_ratio=None, penalty=none, solver=saga; total time=   0.1s\n",
      "[CV] END .....C=0.1, l1_ratio=0.85, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.1, l1_ratio=0.85, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....C=0.1, l1_ratio=0.85, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.001, l1_ratio=0.5, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.001, l1_ratio=0.5, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.001, l1_ratio=0.5, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.001, l1_ratio=0.15, penalty=none, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.001, l1_ratio=0.15, penalty=none, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.001, l1_ratio=0.15, penalty=none, solver=liblinear; total time=   0.0s\n",
      "[CV] END ....C=0.001, l1_ratio=0.5, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....C=0.001, l1_ratio=0.5, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....C=0.001, l1_ratio=0.5, penalty=l1, solver=lbfgs; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  \"(penalty={})\".format(self.penalty)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ........C=1, l1_ratio=0.15, penalty=l1, solver=saga; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  \"(penalty={})\".format(self.penalty)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ........C=1, l1_ratio=0.15, penalty=l1, solver=saga; total time=   0.1s\n",
      "[CV] END ........C=1, l1_ratio=0.15, penalty=l1, solver=saga; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  \"(penalty={})\".format(self.penalty)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......C=1, l1_ratio=None, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .......C=1, l1_ratio=None, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .......C=1, l1_ratio=None, penalty=l1, solver=lbfgs; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
      "  \"(penalty={})\".format(self.penalty)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......C=1, l1_ratio=0.15, penalty=none, solver=saga; total time=   0.1s\n",
      "[CV] END ......C=1, l1_ratio=0.15, penalty=none, solver=saga; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
      "  \"(penalty={})\".format(self.penalty)\n",
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=none)\n",
      "  \"(penalty={})\".format(self.penalty)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......C=1, l1_ratio=0.15, penalty=none, solver=saga; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "51 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 449, in _check_solver\n",
      "    % (solver, penalty)\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "18 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 464, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1473, in fit\n",
      "    % self.l1_ratio\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "21 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 449, in _check_solver\n",
      "    % (solver, penalty)\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_search.py:972: UserWarning: One or more of the test scores are non-finite: [0.79634478 0.79639612 0.79634478        nan 0.79639612 0.79634478\n",
      "        nan 0.79634478 0.79490734 0.79634478        nan 0.79634478\n",
      " 0.79588275 0.79634478        nan        nan 0.79177576 0.79634478\n",
      " 0.79634478 0.79490734 0.79634478        nan 0.79603676        nan\n",
      " 0.79593408        nan 0.79629344 0.79639612 0.79603676        nan\n",
      " 0.79603676 0.79634478        nan 0.79639612 0.79639612        nan\n",
      " 0.79634478 0.79634478        nan 0.79634478 0.79634478 0.79634478\n",
      " 0.79634478        nan        nan        nan        nan 0.79629344\n",
      "        nan 0.79634478]\n",
      "  category=UserWarning,\n",
      "c:\\Users\\SaiAnkith\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  \"(penalty={})\".format(self.penalty)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=LogisticRegression(max_iter=10000,\n",
       "                                                random_state=42),\n",
       "                   n_iter=50, n_jobs=1,\n",
       "                   param_distributions={'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                                        'l1_ratio': [None, 0.15, 0.5, 0.85],\n",
       "                                        'penalty': ['l1', 'l2', 'elasticnet',\n",
       "                                                    'none'],\n",
       "                                        'solver': ['lbfgs', 'liblinear',\n",
       "                                                   'saga']},\n",
       "                   random_state=42, verbose=2)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use RandomizedSearchCV for hyperparameter tuning\n",
    "random_search = RandomizedSearchCV(estimator=clf, param_distributions=param_grid, n_iter=50, cv=3, n_jobs=1, verbose=2, random_state=42)\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best estimator from the random search\n",
    "best_clf = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = best_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'solver': 'liblinear', 'penalty': 'l1', 'l1_ratio': 0.15, 'C': 1}\n",
      "Accuracy: 0.795482546201232\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.90      0.86      3365\n",
      "         1.0       0.72      0.56      0.63      1505\n",
      "\n",
      "    accuracy                           0.80      4870\n",
      "   macro avg       0.77      0.73      0.74      4870\n",
      "weighted avg       0.79      0.80      0.79      4870\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3033  332]\n",
      " [ 664  841]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Random Forest***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Random Forest Classifier\n",
    "clf = RandomForestClassifier(random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   3.2s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.1s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.1s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=  15.4s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=  22.4s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=  13.1s\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  10.6s\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  14.0s\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  14.6s\n",
      "[CV] END bootstrap=True, max_depth=40, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   9.3s\n",
      "[CV] END bootstrap=True, max_depth=40, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   8.9s\n",
      "[CV] END bootstrap=True, max_depth=40, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  13.0s\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   8.0s\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   6.6s\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   6.8s\n",
      "[CV] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   6.6s\n",
      "[CV] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   6.6s\n",
      "[CV] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   4.7s\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=  24.5s\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=  23.1s\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=  20.4s\n",
      "[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  10.4s\n",
      "[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  10.1s\n",
      "[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   8.8s\n",
      "[CV] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   7.3s\n",
      "[CV] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   8.7s\n",
      "[CV] END bootstrap=False, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  11.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   8.8s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   6.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   9.6s\n",
      "[CV] END bootstrap=True, max_depth=40, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   4.0s\n",
      "[CV] END bootstrap=True, max_depth=40, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   2.8s\n",
      "[CV] END bootstrap=True, max_depth=40, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   2.6s\n",
      "[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=  20.4s\n",
      "[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=  20.9s\n",
      "[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=  20.3s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  10.5s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   9.6s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  15.1s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=  17.1s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=  13.4s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=  15.9s\n",
      "[CV] END bootstrap=True, max_depth=40, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   8.6s\n",
      "[CV] END bootstrap=True, max_depth=40, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   8.1s\n",
      "[CV] END bootstrap=True, max_depth=40, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   8.2s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=  13.3s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=  14.2s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=  13.2s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   5.4s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   4.3s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   4.6s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   5.2s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   5.3s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   4.4s\n",
      "[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=400; total time=  18.7s\n",
      "[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=400; total time=  18.1s\n",
      "[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=400; total time=  19.2s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=  15.5s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=  15.1s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=  15.0s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=  12.1s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=  11.1s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=  12.6s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=  12.6s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=  20.6s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=  17.9s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   4.7s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   3.3s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.2s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=  16.5s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=  15.5s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=  15.8s\n",
      "[CV] END bootstrap=False, max_depth=40, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   4.6s\n",
      "[CV] END bootstrap=False, max_depth=40, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   4.4s\n",
      "[CV] END bootstrap=False, max_depth=40, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   4.5s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   6.5s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   6.5s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   6.5s\n",
      "[CV] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   4.5s\n",
      "[CV] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   4.4s\n",
      "[CV] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   4.1s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   8.4s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   6.1s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   7.1s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.7s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.1s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   3.1s\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  18.8s\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  18.1s\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  16.8s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=  14.7s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=  13.7s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=   8.8s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=  10.9s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=  10.9s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=  10.9s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   4.6s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   4.5s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   4.5s\n",
      "[CV] END bootstrap=True, max_depth=40, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   6.7s\n",
      "[CV] END bootstrap=True, max_depth=40, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   7.6s\n",
      "[CV] END bootstrap=True, max_depth=40, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   8.9s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   4.8s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   3.4s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   3.9s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=  17.0s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=  16.9s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=  17.0s\n",
      "[CV] END bootstrap=False, max_depth=40, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  10.5s\n",
      "[CV] END bootstrap=False, max_depth=40, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  11.3s\n",
      "[CV] END bootstrap=False, max_depth=40, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  10.9s\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  10.7s\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  10.8s\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  10.0s\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   4.2s\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   3.7s\n",
      "[CV] END bootstrap=False, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   3.6s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=  14.4s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=  12.8s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=  13.6s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   3.7s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   3.4s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   3.7s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   3.6s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   3.0s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   3.2s\n",
      "[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  11.1s\n",
      "[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  10.4s\n",
      "[CV] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  10.2s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=  17.5s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=  16.9s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=  17.4s\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=  21.1s\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=  20.2s\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=  21.7s\n",
      "[CV] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  15.1s\n",
      "[CV] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  14.7s\n",
      "[CV] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  14.3s\n",
      "[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=400; total time=  20.3s\n",
      "[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=400; total time=  19.6s\n",
      "[CV] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=400; total time=  21.2s\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  11.1s\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  11.8s\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  10.2s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=400; total time=   8.7s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=400; total time=  10.4s\n",
      "[CV] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=400; total time=   8.8s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=  11.2s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=  11.4s\n",
      "[CV] END bootstrap=True, max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=  11.7s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(random_state=42),\n",
       "                   n_iter=50, n_jobs=1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [None, 10, 20, 30, 40, 50],\n",
       "                                        'max_features': ['auto', 'sqrt',\n",
       "                                                         'log2'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [100, 200, 300, 400,\n",
       "                                                         500]},\n",
       "                   random_state=42, verbose=2)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use RandomizedSearchCV for hyperparameter tuning\n",
    "random_search = RandomizedSearchCV(estimator=clf, param_distributions=param_grid, n_iter=50, cv=3, n_jobs=1, verbose=2, random_state=42)\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best estimator from the random search\n",
    "best_clf = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = best_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_estimators': 300, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth': 40, 'bootstrap': True}\n",
      "Accuracy: 0.7919917864476386\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.90      0.86      3365\n",
      "         1.0       0.71      0.55      0.62      1505\n",
      "\n",
      "    accuracy                           0.79      4870\n",
      "   macro avg       0.77      0.72      0.74      4870\n",
      "weighted avg       0.78      0.79      0.78      4870\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3036  329]\n",
      " [ 684  821]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
