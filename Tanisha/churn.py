# -*- coding: utf-8 -*-
"""churn.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BQL3AF88op8CNv_2qL9mM1ITZCm_n73z
"""

#importing libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as  sns

#read the data set
data = pd.read_csv('chrundata.csv')

data.head()

data.tail()

"""Sanity check of data"""

#shape
data.shape

#info
data.info()

# finding missing values
data.isnull().sum()

# finding duplicates
data.duplicated().sum()

"""Data Preprocessing steps"""

# convert data type of variables which are misclassified
for column in data.columns:
    if data[column].dtype == 'object':
        try:
            data[column] = pd.to_numeric(data[column])
        except ValueError:
            pass

print("\nAfter Converting Data Types:")
print(data.shape)

# removing duplicate records
data = data.drop_duplicates()
print("\nAfter Removing Duplicates:")
print(data.shape)

# removing unique value variables
unique_val_cols = [col for col in data.columns if data[col].nunique() == 1]
data = data.drop(columns=unique_val_cols)
print("Columns with unique values:", unique_val_cols)

# removing zero variance variables
zero_variance_cols = [col for col in data.columns if data[col].var() == 0]
data = data.drop(columns=zero_variance_cols)
print("Columns with zero variance:", zero_variance_cols)

"""Outlier Treatment"""

# Using Boxplot: Q3+(1.5*IQR)& Q1-(1.5*IQR)
data= pd.read_csv('chrundata.csv')
Q1 = data.quantile(0.15)
Q3 = data.quantile(0.85)
IQR = Q3 - Q1
lower_bound = Q1-1.5*IQR
upper_bound = Q3+1.5*IQR


# filter out the outliers
outliers_removed = data[~((data < lower_bound)|(data > upper_bound)).any(axis=1)]
print("identified outliers using IQR method:")
print(outliers_removed.shape)

# capping and flooring
df = data.copy()
lower_threshold = data.quantile(0.05)
upper_threshold = data.quantile(0.95)
# Clip the data
cap_data = data.clip(lower=lower_threshold, upper=upper_threshold, axis=1)
print(f"Shape of data after capping and flooring: {cap_data.shape}")

"""Missing Value Treatment"""

from sklearn.impute import SimpleImputer
# Remove records if NAs are less than 5%
threshold = 0.05
df = data.dropna(thresh=(1-threshold) * data.shape[1], axis=0)

# Remove columns if NAs are 50% or more
data = data.dropna(thresh=0.5 * data.shape[0], axis=1)

# Impute missing values
imputer_num = SimpleImputer(strategy='mean')
imputer_cat = SimpleImputer(strategy='most_frequent')
for column in data.columns:
    if data[column].dtype in ['int64', 'float64']:
        data[column] = imputer_num.fit_transform(data[[column]])
    else:
        data[column] = imputer_cat.fit_transform(data[[column]])

#checking for missing values
missing_values = data.isnull().sum()
print("total missing values after treatment:", missing_values)
print("shape after missing value treatment:", data.shape)

"""Highly correlated variables"""

#removing the highly correlated variables
corr_matrix = data.corr().abs()
upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))
to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.95)]
data = data.drop(columns=to_drop)
print("highly correlated features removed:", to_drop)

print("shape of data after removing highly correlated variables:", data.shape)

"""Multicollinearity (VIF>5)"""

from statsmodels.stats.outliers_influence import variance_inflation_factor
X = data.select_dtypes(include=[np.number])
vif = pd.DataFrame()
vif["VIF"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]
vif["Variable"] = X.columns

# Drop variables with VIF > 5
variables_to_drop = vif[vif["VIF"] > 5]["Variable"]
data = data.drop(columns=variables_to_drop)


print("variables dropped:", variables_to_drop)
print("shape of data after removing multicollinearity:", data.shape)

"""Logistic Regression"""

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score

data = pd.read_csv('chrundata.csv')

X = data.drop('target', axis=1)
y = data['target']

# split the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# check the shape of the splits
X_train.shape, X_test.shape, y_train.shape, y_test.shape

# Scaling the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Instantiate the logistic regression model with increased max_iter
model = LogisticRegression(max_iter=1000)

# Training the model on the scaled data
model.fit(X_train_scaled, y_train)

# Predicting on the test set
y_pred = model.predict(X_test_scaled)

# Evaluating the model
accuracy = accuracy_score(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)
class_report = classification_report(y_test, y_pred)

print("Accuracy:", accuracy)
print("Confusion Matrix:\n", conf_matrix)
print("Classification Report:\n", class_report)

"""Random Forest"""

from sklearn.ensemble import RandomForestClassifier
# Initialize the RandomForestClassifier
rf = RandomForestClassifier(random_state=42)

# Train the model on the training data
rf.fit(X_train, y_train)

# Predict on the test set
y_pred = rf.predict(X_test)

# Evaluate the model
print("Initial Model Evaluation:")
print(classification_report(y_test, y_pred))
print(f"Accuracy: {accuracy_score(y_test, y_pred)}")

"""Decision Trees"""

from sklearn.tree import DecisionTreeClassifier
# Initialize the model
model = DecisionTreeClassifier(random_state=42)

# Train the model
model.fit(X_train, y_train)

# Predictions on the test set
y_pred = model.predict(X_test)

# Model evaluation
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))
print("Accuracy:", accuracy_score(y_test, y_pred))

# hyperparameter tuning
param_grid = {
    'criterion': ['gini', 'entropy'],
    'max_depth': [None, 10, 20, 30, 40, 50],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
# Initialize GridSearchCV
grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)

# Fit the model
grid_search.fit(X_train, y_train)

print("Best parameters:", grid_search.best_params_)

# Cross- Validation
cv_scores = cross_val_score(grid_search.best_estimator_, X_train, y_train, cv=5)
print("Cross-validation scores:", cv_scores)
print("Mean cross-validation score:", np.mean(cv_scores))

# Final model with best parameters
final_model = grid_search.best_estimator_

# Train the final model
final_model.fit(X_train, y_train)

# Predictions on the test set
final_y_pred = final_model.predict(X_test)

# Model evaluation
print(confusion_matrix(y_test, final_y_pred))
print(classification_report(y_test, final_y_pred))
print("Accuracy:", accuracy_score(y_test, final_y_pred))

